toParse = """Epoch     Train        Val          Train        Val          val_macro_..   tra_macro_..   time            
[I]   -------   ----------   ----------   ----------   ----------   ------------   ------------   --------------  
[I]   1         0.3471       0.3422       0.8591       0.8625       8.65           8.83           0:01:45.216041  
[I]   2         0.3273       0.3191       0.8637       0.8658       10.88          10.34          0:01:45.151993  
[I]   3         0.3136       0.3117       0.8675       0.8697       17.53          15.99          0:01:44.649093  
[I]   4         0.2919       0.3061       0.8769       0.8753       27.91          28.42          0:01:44.480687  
[I]   5         0.2788       0.3027       0.8828       0.8806       27.19          28.68          0:01:44.204697  
[I]   6         0.2672       0.2795       0.8864       0.8849       32.79          34.59          0:01:44.442679  
[I]   7         0.2597       0.2746       0.8909       0.8832       38.57          40.25          0:01:44.267211  
[I]   8         0.2489       0.2512       0.8929       0.8931       44.60          50.52          0:01:44.144798  
[I]   9         0.2455       0.2648       0.8957       0.8859       41.87          48.10          0:01:42.990774  
[I]   10        0.2350       0.2741       0.9029       0.8862       43.84          52.49          0:01:42.963229  
[I]   11        0.2280       0.2511       0.9044       0.8977       47.04          52.79          0:01:42.675107  
[I]   12        0.2238       0.2451       0.9057       0.8947       45.48          51.19          0:01:42.660128  
[I]   13        0.2216       0.2829       0.9083       0.8865       47.18          55.82          0:01:42.754413  
[I]   14        0.2108       0.2487       0.9137       0.8937       45.84          53.71          0:01:42.723735  
[I]   15        0.2100       0.2427       0.9100       0.8997       52.31          55.01          0:01:42.626003  
[I]   16        0.1989       0.2307       0.9169       0.9072       52.63          61.36          0:01:42.561081  
[I]   17        0.1979       0.2325       0.9160       0.9043       52.03          61.99          0:01:42.675065  
[I]   18        0.1924       0.2937       0.9199       0.8816       38.52          46.57          0:01:42.534373  
[I]   19        0.1976       0.2346       0.9175       0.9033       54.32          60.47          0:01:42.596547  
[I]   20        0.1875       0.2205       0.9195       0.9145       56.65          65.06          0:01:42.695892  
[I]   21        0.1856       0.2507       0.9231       0.8974       48.68          58.24          0:01:42.747659  
[I]   22        0.1812       0.2487       0.9256       0.9059       52.35          61.73          0:01:42.533742  
[I]   23        0.1835       0.2054       0.9246       0.9168       59.30          66.42          0:01:42.686502  
[I]   24        0.1742       0.2026       0.9294       0.9201       61.80          69.51          0:01:42.409773  
[I]   25        0.1722       0.2033       0.9288       0.9148       60.28          70.30          0:01:42.619174  
[I]   26        0.1677       0.1886       0.9290       0.9240       66.58          74.36          0:01:42.633112  
[I]   27        0.1713       0.1897       0.9297       0.9253       67.35          77.09          0:01:42.562687  
[I]   28        0.1626       0.2072       0.9336       0.9214       63.57          71.59          0:01:42.878148  
[I]   29        0.1532       0.1873       0.9381       0.9250       65.23          74.89          0:01:42.608342  
[I]   30        0.1510       0.1997       0.9390       0.9207       65.60          75.30          0:01:42.721054  
[I]   31        0.1554       0.1908       0.9372       0.9250       66.40          77.06          0:01:42.734043  
[I]   32        0.1575       0.2374       0.9360       0.9105       57.87          66.23          0:01:42.552946  
[I]   33        0.1460       0.2066       0.9418       0.9174       63.70          75.48          0:01:42.691654  
[I]   34        0.1489       0.2065       0.9405       0.9168       63.89          77.73          0:01:42.596097  
[I]   35        0.1526       0.2061       0.9375       0.9227       64.14          75.91          0:01:42.648390  
[I]   36        0.1464       0.2079       0.9416       0.9234       64.95          78.04          0:01:42.535463  
[I]   37        0.1695       0.2129       0.9304       0.9197       59.25          67.31          0:01:42.733315  
[I]   38        0.1530       0.2979       0.9385       0.8872       47.05          57.95          0:01:42.463470  
[I]   39        0.1527       0.1954       0.9367       0.9276       66.89          79.06          0:01:42.660751  
[I]   40        0.1389       0.1906       0.9432       0.9286       69.24          81.46          0:01:42.820697  
[I]   41        0.1364       0.1819       0.9449       0.9309       70.46          82.55          0:01:42.716168  
[I]   42        0.1368       0.2666       0.9449       0.8984       55.07          66.95          0:01:42.559071  
[I]   43        0.1360       0.2223       0.9461       0.9109       61.31          73.74          0:01:42.797044  
[I]   44        0.1288       0.1935       0.9503       0.9217       67.09          80.41          0:01:42.679812  
[I]   45        0.1308       0.1795       0.9486       0.9365       73.79          84.53          0:01:42.503840  
[I]   46        0.1213       0.2082       0.9522       0.9237       66.21          79.71          0:01:42.753104  
[I]   47        0.1277       0.2128       0.9478       0.9194       65.48          79.51          0:01:42.600463  
[I]   48        0.1245       0.1783       0.9506       0.9339       72.32          85.75          0:01:42.662014  
[I]   49        0.1311       0.2044       0.9481       0.9204       64.11          80.24          0:01:42.805626  
[I]   50        0.1229       0.1847       0.9515       0.9289       69.89          85.42          0:01:42.670464  
[I]   51        0.1177       0.1794       0.9541       0.9299       69.56          88.10          0:01:42.607070  
[I]   52        0.1178       0.2354       0.9542       0.9092       60.16          71.89          0:01:42.725093  
[I]   53        0.1246       0.1853       0.9509       0.9270       67.02          85.20          0:01:42.550743  
[I]   54        0.1112       0.1969       0.9557       0.9243       66.11          81.61          0:01:42.398256  
[I]   55        0.1193       0.2097       0.9533       0.9201       65.44          82.05          0:01:42.406725  
[I]   56        0.1167       0.1944       0.9539       0.9260       66.50          81.92          0:01:42.599237  
[I]   57        0.1110       0.1937       0.9566       0.9276       69.36          84.06          0:01:42.647475  
[I]   58        0.1089       0.2372       0.9578       0.9099       62.48          77.05          0:01:42.594320  
[I]   59        0.1296       0.1772       0.9505       0.9349       72.57          86.22          0:01:42.541726  
[I]   60        0.1197       0.2229       0.9541       0.9151       64.44          79.87          0:01:42.494115  
[I]   61        0.1109       0.1708       0.9565       0.9355       72.41          86.27          0:01:42.581601"""

val_macro = []
val_loss = []
val_binary_accuracy = []
for line in toParse.split("\n")[2:]:
    data = " ".join(line.split()).split(" ")
    print(data)
    val_macro.append(float(data[-3])/100.0)
    val_loss.append(float(data[3]))
    val_binary_accuracy.append(float(data[5]))

import matplotlib.pyplot as plt
import numpy as np

plt.figure(0, figsize=(9,6))
plt.subplot(111)
plt.plot(val_macro, label="val_f1")
plt.plot(val_loss, label="val_loss")
plt.plot(val_binary_accuracy, label="val_bin_acc")
plt.title("Baseline run")
plt.legend()
plt.show()
