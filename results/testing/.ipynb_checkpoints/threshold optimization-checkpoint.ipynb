{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load the required modules\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from keras.models import model_from_json, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import librosa.display\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from datasetGenerator import DCASE2018\n",
    "\n",
    "confusionMatrices = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel\n"
     ]
    }
   ],
   "source": [
    "featRoot = \"/homeLocal/eriador/Documents/Corpus/DCASE2018/features_2/\"\n",
    "metaRoot = \"/homeLocal/eriador/Documents/Corpus/DCASE2018/meta\"\n",
    "feat =  [\"mel\"]\n",
    "normalizer = None\n",
    "\n",
    "dataset = DCASE2018(\n",
    "        featureRoot=featRoot,\n",
    "        metaRoot=metaRoot,\n",
    "        features=feat,\n",
    "        expandWithUod=False,\n",
    "        validationPercent=0.2,\n",
    "        normalizer=normalizer\n",
    "    )\n",
    "\n",
    "# load the model\n",
    "modelJsonPath = \"/homeLocal/eriador/Documents/DCASE2018/results/testing/mel_old_noBlank_timeReduction2/oldMel_noBlank_reduce2_model.json\"\n",
    "modelWeightPath = \"/homeLocal/eriador/Documents/DCASE2018/results/testing/mel_old_noBlank_timeReduction2/oldMel_noBlank_reduce2_weight.h5py\"\n",
    "\n",
    "with open(modelJsonPath, \"r\") as modelJsonFile:\n",
    "    model = model_from_json(modelJsonFile.read())\n",
    "model.load_weights(modelWeightPath)\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the predictionï¿¼\n",
    "vPred = dataset.validationDataset[\"mel\"][\"input\"]\n",
    "vTrue = dataset.validationDataset[\"mel\"][\"output\"]\n",
    "\n",
    "# calc metrics for each classes separately\n",
    "prediction = model.predict(np.array(vPred))\n",
    "\n",
    "# apply basic threshold (0.5)\n",
    "basic_predic = copy.copy(prediction[:])\n",
    "basic_predic[basic_predic > 0.5] = 1\n",
    "basic_predic[basic_predic < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc confusion matrix\n",
    "classes  = \"Alarm_bell_ringing,Speech,Dog,Cat,Vacuum_cleaner,Dishes,Frying,Elec_shav_tooth,Blender,Running_water\".split(\",\")\n",
    "\n",
    "# reshape and format\n",
    "def reshapeAndFormat(predicted, useBlank: bool = True):\n",
    "    global classes\n",
    "    blank = \"blank\"\n",
    "    true = []\n",
    "    pred = []\n",
    "\n",
    "    nbClsTrue = [sum(cls) for cls in vTrue]\n",
    "    nbClsPred = [int(sum(cls)) for cls in predicted]\n",
    "        \n",
    "\n",
    "    for i in range(len(vTrue)):\n",
    "        # true\n",
    "        cptTrue = 0\n",
    "        for cls in range(len(vTrue[i])):\n",
    "            if vTrue[i][cls] == 1:\n",
    "                true.append(classes[cls])\n",
    "                cptTrue += 1\n",
    "\n",
    "        #pred\n",
    "        cptPred = 0\n",
    "        for cls in range(len(predicted[i])):\n",
    "            if int(predicted[i][cls]) == 1:\n",
    "                pred.append(classes[cls])\n",
    "                cptPred += 1\n",
    "\n",
    "        # augment the data for missing or extra class\n",
    "        if useBlank:\n",
    "            blank = \"not_predicted\"\n",
    "            \n",
    "            if cptTrue < cptPred:\n",
    "                while cptTrue < cptPred:\n",
    "                    true.append(blank)\n",
    "                    cptTrue += 1\n",
    "\n",
    "            elif cptPred < cptTrue:\n",
    "                while cptPred < cptTrue:\n",
    "                    pred.append(blank)\n",
    "                    cptPred += 1\n",
    "        else:\n",
    "            classes  = \"Alarm_bell_ringing,Speech,Dog,Cat,Vacuum_cleaner,Dishes,Frying,Elec_shav_tooth,Blender,Running_water\".split(\",\")\n",
    "            # add as much element as it should be using the nbTrue maximums from the non tresholded prediction results\n",
    "            if cptPred != cptTrue:\n",
    "                # remove the last element added to pred\n",
    "                if cptPred != 0:\n",
    "                    pred = pred[:-cptPred]\n",
    "                \n",
    "                \n",
    "                pos = []\n",
    "                line = copy.copy(prediction[i])\n",
    "                for i in range(cptTrue):\n",
    "                    cPos = np.where(line==max(line))[0][0]\n",
    "                    pos.append(cPos)\n",
    "                    np.delete(line, cPos)\n",
    "                    \n",
    "                for p in pos:\n",
    "                    pred.append(classes[p])\n",
    "                                \n",
    "    return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the confusion matrix using a sklearn MinMaxScaler\n",
    "def scaleConfusion(confusion: np.array) -> np.array:\n",
    "    scaledConfusion = []\n",
    "    for line in confusion:\n",
    "        scaledLine = line / sum(line)\n",
    "        scaledConfusion.append(scaledLine)\n",
    "        \n",
    "    return scaledConfusion\n",
    "\n",
    "def displayConfusion(matrix: np.array, classes: list, bcolor: str =\"Blues\", bounds: tuple = (-1,1)):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    #plt.title(os.path.basename(modelJsonPath))\n",
    "    plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "    plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\n",
    "\n",
    "    plt.imshow(matrix)\n",
    "    plt.xticks([i for i in range(len(classes))], classes, rotation=80)\n",
    "    plt.yticks([i for i in range(len(classes))], classes)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=18)\n",
    "\n",
    "    # add text on the matrix\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            value = matrix[j][i]\n",
    "            displayValue = \"%.2f\" % matrix[j][i]\n",
    "            displayValue = displayValue[:]\n",
    "            if value > 0.5: color=\"#b9b9b9\"\n",
    "            else: color=\"#232323\"\n",
    "\n",
    "            plt.text(i, j, displayValue, fontsize=14, color=color, ha=\"center\", va=\"center\")\n",
    "            \n",
    "    plt.set_cmap(bcolor)\n",
    "    plt.clim(*bounds)\n",
    "    plt.colorbar(cmap=bcolor)\n",
    "    \n",
    "# ---- compute appprint(pred)roximative confusion matrix ----\n",
    "def calcConfusion(prediction, display: bool = True):\n",
    "    true, pred = reshapeAndFormat(prediction, False)\n",
    "    confusion = confusion_matrix(true, pred, labels=classes)\n",
    "    scaledConfusion = scaleConfusion(confusion)\n",
    "    \n",
    "    if display:\n",
    "        displayConfusion(scaledConfusion, classes)\n",
    "    \n",
    "    return np.array(scaledConfusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold with f1 mean of: 0.7772    , progress: 99.97 %\n",
      "0.03315789473684208\n",
      "[0.61458151 0.46398423 0.60129154 0.62364478 0.55717497 0.37724157\n",
      " 0.39991857 0.35649953 0.34604371 0.33839593]\n",
      "original f1 mean: 75.28\n",
      "original recall: 82.96\n",
      "original precision: 71.88\n",
      "best f1 mean: 77.72\n",
      "best recall: 81.55\n",
      "best precision: 77.20\n",
      "Alarm_bell_ringing 0.6146\n",
      "Speech 0.4640\n",
      "Dog 0.6013\n",
      "Cat 0.6236\n",
      "Vacuum_cleaner 0.5572\n",
      "Dishes 0.3772\n",
      "Frying 0.3999\n",
      "Elec_shav_tooth 0.3565\n",
      "Blender 0.3460\n",
      "Running_water 0.3384\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2a058af4f2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best precision: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean p\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclsInd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclsInd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclsInd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mpredLast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "def applyThreshold(thresh) -> list:\n",
    "    pred = copy.copy(prediction)\n",
    "    \n",
    "    for clsInd in range(len(pred.T)):\n",
    "        pred.T[clsInd][pred.T[clsInd] > thresh[clsInd]] = 1\n",
    "        pred.T[clsInd][pred.T[clsInd] <= thresh[clsInd]] = 0\n",
    "        \n",
    "    return pred\n",
    "\n",
    "def initThresholds():\n",
    "    return np.array([random.randint(40, 60) / 100 for _ in range(10)])\n",
    "\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "def calcDelta(thresholds, weight):\n",
    "    output = []\n",
    "    for th in thresholds:\n",
    "        g = gaussian(th, 0.5, 0.08)\n",
    "        output.append((random.random() * 2*g - g) * weight)\n",
    "    return np.array(output)\n",
    "\n",
    "thresholds = [0.5 for _ in range(10)]\n",
    "pred0 = applyThreshold(thresh=thresholds)\n",
    "f10 = f1_score(pred0, vTrue, average=None)\n",
    "r0 = recall_score(pred0, vTrue, average=None)\n",
    "p0 = precision_score(pred0, vTrue, average=None)\n",
    "init = {\"thresholds\": thresholds, \"mean f1\": f10.mean(), \"mean r\": r0.mean(), \"mean p\": p0.mean(), \"f1\" : f10}\n",
    "best = {\"thresholds\": thresholds, \"mean f1\": f10.mean(), \"mean r\": r0.mean(), \"mean p\": p0.mean(), \"f1\" : f10}\n",
    "curve = []\n",
    "\n",
    "\n",
    "metaIter = 100\n",
    "for j in range(metaIter):\n",
    "    nbIter = 30\n",
    "    nbIterTotal = nbIter * metaIter\n",
    "    weight = 0.07\n",
    "    decay = weight / (nbIter *1.9)\n",
    "    thresholds = initThresholds()\n",
    "    for i in range(nbIter):\n",
    "        delta = calcDelta(thresholds, weight)\n",
    "        thresholds += delta\n",
    "        weight -= decay\n",
    "\n",
    "        nPred = applyThreshold(thresholds)\n",
    "        f1 = f1_score(nPred, vTrue, average=None)\n",
    "        r = recall_score(nPred, vTrue, average=None)\n",
    "        p = precision_score(nPred, vTrue, average=None)\n",
    "\n",
    "        if f1.mean() > best[\"mean f1\"]:\n",
    "            best[\"thresholds\"] = thresholds\n",
    "            best[\"mean f1\"] = f1.mean()\n",
    "            best[\"mean r\"] = r.mean()\n",
    "            best[\"mean p\"] = p.mean()\n",
    "            best[\"f1\"] = f1\n",
    "            curve.append(f1.mean())\n",
    "\n",
    "        percent = (j * nbIter + i) / nbIterTotal * 100\n",
    "        clear_output(wait=True)\n",
    "        print(\"best threshold with f1 mean of: %-*.4f, progress: %.2f %%\" % (10, best[\"mean f1\"], percent) )\n",
    "\n",
    "print(weight)\n",
    "print(thresholds)\n",
    "print(\"original f1 mean: %.2f\" % (init[\"mean f1\"] * 100))\n",
    "print(\"original recall: %.2f\" %  (init[\"mean r\"] * 100))\n",
    "print(\"original precision: %.2f\" %  (init[\"mean p\"] * 100))\n",
    "print(\"best f1 mean: %.2f\" %  (best[\"mean f1\"] * 100))\n",
    "print(\"best recall: %.2f\" %  (best[\"mean r\"] * 100))\n",
    "print(\"best precision: %.2f\" %  (best[\"mean p\"] * 100))\n",
    "for clsInd in range(len(classes)):\n",
    "    print(classes[clsInd], \"%.4f\" % thresholds[clsInd])\n",
    "    \n",
    "predLast = applyThreshold(thresholds)\n",
    "conf0 = calcConfusion(pred0, False)\n",
    "confn = calcConfusion(predLast, False)\n",
    "displayConfusion(conf0 - confn, classes, \"RdBu\", bounds=(-0.15, 0.15))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "x = np.linspace(0.2, 0.8, 1000)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False\n",
    "plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = True\n",
    "plt.plot(x, gaussian(x, 0.5, 0.08) * 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
