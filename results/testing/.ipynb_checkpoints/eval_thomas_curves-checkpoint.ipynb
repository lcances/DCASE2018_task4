{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# Load the required modules\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import os\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from datasetGenerator import DCASE2018\n",
    "from Binarizer import Binarizer\n",
    "from Encoder import Encoder\n",
    "import pickle\n",
    "\n",
    "from evaluation_measures import event_based_evaluation\n",
    "from dcase_util.containers import MetaDataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pkl file\n",
    "# pkl_file='../test_predictions/multitask_100epochs.pkl'\n",
    "#pkl_file='../test_predictions/dico_10epochs_MIL_cnn.pkl'\n",
    "#pkl_file=\"dico_thomas_last.pkl\"\n",
    "pkl_file=\"eval_880_dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286\"\n",
    "#pkl_file='../test_predictions/dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286.pkl' # best: 24.46\n",
    "# pkl_file='../test_predictions/dico_10epochs_MIL_cnn_classif_cnn_70epochs_final_xtrain_f1_0.8762.pkl'\n",
    "# pkl_file='../test_predictions/dico_10epochs_MIL_cnn_crnn_adaptation.pkl'\n",
    "# pkl_file='../test_predictions/test_thresh_0_5_dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286.pkl'\n",
    "\n",
    "# pkl_file='../eval_predictions/eval_880_dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[\"Y0UN02RkbG_U_7.000_17.000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel\n"
     ]
    }
   ],
   "source": [
    "# format the curves to be used by the Encoder (need ALL curves)\n",
    "featRoot = \"/baie/corpus/DCASE2018/task4/FEATURES/\"\n",
    "metaRoot = \"/baie/corpus/DCASE2018/task4/metadata\"\n",
    "feat =  [\"mel\"]\n",
    "normalizer = None\n",
    "\n",
    "dataset = DCASE2018(\n",
    "        featureRoot=featRoot,\n",
    "        metaRoot=metaRoot,\n",
    "        features=feat,\n",
    "        expandWithUod=False,\n",
    "        validationPercent=0.2,\n",
    "        normalizer=normalizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y0UN02RkbG_U_7.000_17.000', 'Y-6-rh8kbZf0_40.000_50.000', 'Y6ocUrRBIuls_340.000_350.000', 'Y7wPIQMsalK8_70.000_80.000', 'Y-dDpGRPHzM0_30.000_40.000']\n",
      "['Y0hAK5f1tDok_30.000_40.000', 'Y-Y2x_3lyCqY_10.000_20.000', 'YDcuiRMRt1gs_30.000_40.000', 'YhPwyvO-Bzt8_570.000_580.000', 'YBfsxrvRNJe0_100.000_110.000']\n"
     ]
    }
   ],
   "source": [
    "testListFile = [f[:-8] for f in dataset.testFileList]\n",
    "print(testListFile[:5])\n",
    "print(list(data.keys())[:5])\n",
    "nbFrame = 431\n",
    "\n",
    "# rearange list of results\n",
    "results = []\n",
    "for f in testListFile:\n",
    "    info = data[f]\n",
    "    \n",
    "    curves = np.array([[0]*dataset.nbClass for _ in range(nbFrame)], dtype=np.float32)\n",
    "    \n",
    "    for cls in info:\n",
    "        index = DCASE2018.class_correspondance[cls]\n",
    "        curves[:,index] = info[cls]\n",
    "        \n",
    "    results.append(curves)\n",
    "\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smooting using the smooth moving average algorithm\n",
      "perform evaluation ...\n",
      "Event based metrics (onset-offset)\n",
      "========================================\n",
      "  Evaluated length                  : 2616.88 sec\n",
      "  Evaluated files                   : 288 \n",
      "  Evaluate onset                    : True \n",
      "  Evaluate offset                   : True \n",
      "  T collar                          : 200.00 ms\n",
      "  Offset (length)                   : 20.00 %\n",
      "\n",
      "  Overall metrics (micro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 23.06 %\n",
      "    Precision                       : 24.27 %\n",
      "    Recall                          : 21.96 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 1.43 \n",
      "    Substitution rate               : 0.04 \n",
      "    Deletion rate                   : 0.74 \n",
      "    Insertion rate                  : 0.65 \n",
      "\n",
      "  Class-wise average metrics (macro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 24.58 %\n",
      "    Precision                       : 24.64 %\n",
      "    Recall                          : 24.96 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 1.45 \n",
      "    Deletion rate                   : 0.75 \n",
      "    Insertion rate                  : 0.70 \n",
      "  \n",
      "\n",
      "  Class-wise metrics\n",
      "  ======================================\n",
      "    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n",
      "    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n",
      "    Alarm_bell.. | 112     93    | 28.3%    31.2%    25.9%  | 1.31     0.74     0.57   |\n",
      "    Blender      | 40      39    | 10.1%    10.3%    10.0%  | 1.77     0.90     0.88   |\n",
      "    Cat          | 82      94    | 48.9%    45.7%    52.4%  | 1.10     0.48     0.62   |\n",
      "    Dishes       | 122     49    | 0.0%     0.0%     0.0%   | 1.40     1.00     0.40   |\n",
      "    Dog          | 126     100   | 18.6%    21.0%    16.7%  | 1.46     0.83     0.63   |\n",
      "    Electric_s.. | 28      28    | 28.6%    28.6%    28.6%  | 1.43     0.71     0.71   |\n",
      "    Frying       | 24      36    | 26.7%    22.2%    33.3%  | 1.83     0.67     1.17   |\n",
      "    Running_wa.. | 76      60    | 10.3%    11.7%    9.2%   | 1.61     0.91     0.70   |\n",
      "    Speech       | 260     288   | 22.3%    21.2%    23.5%  | 1.64     0.77     0.87   |\n",
      "    Vacuum_cle.. | 36      33    | 52.2%    54.5%    50.0%  | 0.92     0.50     0.42   |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "# segments = encoder.encode(results, method=\"hysteresis\", high=0.1, low=0.05, smooth=\"smoothMovingAvg\")   # 6.66 %\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.05, low=0.05)#, smooth=\"smoothMovingAvg\")  # 20.75 %\n",
    "segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07, smooth=\"smoothMovingAvg\", window_len=19)  # 21.50 %\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07)#, smooth=\"smoothMovingAvg\")\n",
    "toEvaluate = encoder.parse(segments, dataset.testFileList)\n",
    "\n",
    "print(\"perform evaluation ...\")                                                                                                                                                                                                                           \n",
    "with open(\"toEvaluate.csv\", \"w\") as f:                    \n",
    "    f.write(\"filename\\tonset\\toffset\\tevent_label\\n\")                                                                                                                                                                                                             \n",
    "    f.write(toEvaluate)                                                                                                                                                                                                                                           \n",
    "\n",
    "perso_event_list = MetaDataContainer()                                                                                                                                                                                                                            \n",
    "perso_event_list.load(filename=\"toEvaluate.csv\")                                                                                                                                                                                                                  \n",
    "\n",
    "ref_event_list = MetaDataContainer()                                                                                                                                                                                                                              \n",
    "ref_event_list.load(filename=dataset.meta_test)                                                                                                                                                                                                                   \n",
    "\n",
    "event_based_metric = event_based_evaluation(ref_event_list, perso_event_list)                                                                                                                                                                                     \n",
    "print(event_based_metric)                                                                                                                                                                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 880/880 [00:00<00:00, 924.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(880, 64, 431, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the evaluation set\n",
    "featEvalPath = \"/baie/corpus/DCASE2018/task4/FEATURES/eval/mel\"\n",
    "featEvalList = os.listdir(featEvalPath)\n",
    "\n",
    "# load the meta data ----\n",
    "metaPath = \"/baie/corpus/DCASE2018/task4/metadata/eval.csv\"\n",
    "with open(metaPath, \"r\") as metaFile:\n",
    "    metadata = metaFile.read().splitlines()[1:]\n",
    "    \n",
    "metadata = [i.split(\"\\t\") for i in metadata]\n",
    "\n",
    "# load the features\n",
    "featEval = []\n",
    "for file in tqdm.tqdm(featEvalList):\n",
    "    path = os.path.join(featEvalPath, file)\n",
    "    feature = np.load(path)\n",
    "       \n",
    "    # preprocessing\n",
    "    feature = np.expand_dims(feature, axis=-1)\n",
    "    featEval.append(feature)\n",
    "    \n",
    "featEval = np.array(featEval)\n",
    "featEval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YX-jJxA53SFI_130.000_140.000', 'YBJimHxqGfig_50.000_60.000', 'YC7TihoHf_hM_20.000_30.000', 'Y-wQ8El8J_dE_30.000_40.000', 'Y63Qy15I3QGE_30.000_40.000']\n",
      "['Y8UQI59N-bAs_10.000_20.000', 'YIUdIAuoqEbM_0.000_10.000', 'YQtpn66PvyUA_3.000_13.000', 'Y8mT-l6lcBsk_260.000_270.000', 'YKS2aTlLJPo8_90.000_100.000']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(880, 431, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpListFile = [f[:-8] for f in featEvalList]\n",
    "print(tmpListFile[:5])\n",
    "print(list(data.keys())[:5])\n",
    "nbFrame = 431\n",
    "\n",
    "# rearange list of results\n",
    "results = []\n",
    "for f in tmpListFile:\n",
    "    info = data[f]\n",
    "    \n",
    "    curves = np.array([[0]*dataset.nbClass for _ in range(nbFrame)], dtype=np.float32)\n",
    "    \n",
    "    for cls in info:\n",
    "        index = DCASE2018.class_correspondance[cls]\n",
    "        curves[:,index] = info[cls]\n",
    "        \n",
    "    results.append(curves)\n",
    "\n",
    "results = np.array(results)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smooting using the smooth moving average algorithm\n",
      "perform evaluation ...\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "# segments = encoder.encode(results, method=\"hysteresis\", high=0.1, low=0.05, smooth=\"smoothMovingAvg\")   # 6.66 %\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.05, low=0.05)#, smooth=\"smoothMovingAvg\")  # 20.75 %\n",
    "segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07, smooth=\"smoothMovingAvg\")  # 21.50 %\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07)#, smooth=\"smoothMovingAvg\")\n",
    "toEvaluate = encoder.parse(segments, tmpListFile)\n",
    "\n",
    "print(\"perform evaluation ...\")                                                                                                                                                                                                                           \n",
    "with open(\"toto_toEvaluate.csv\", \"w\") as f:                    \n",
    "    f.write(\"filename\\tonset\\toffset\\tevent_label\\n\")                                                                                                                                                                                                             \n",
    "    f.write(toEvaluate)                                                                                                                                                                                                                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_fname='../submissions/0/sub0_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286_macrof1_0.2446.txt'\n",
    "print(\"Saving final results in %s\"%submission_fname)                                                                                                                                                                                                                \n",
    "with open(submission_fname, \"w\") as f:                                                                                                                                                                                                                             \n",
    "    f.write(str(event_based_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in segments[0]:\n",
    "    print(\"cls: \", cls, segments[0][cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toEvaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
