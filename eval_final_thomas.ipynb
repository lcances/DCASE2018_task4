{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# Load the required modules\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import os\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from datasetGenerator import DCASE2018\n",
    "from Binarizer import Binarizer\n",
    "from Encoder import Encoder\n",
    "import pickle\n",
    "\n",
    "from evaluation_measures import event_based_evaluation\n",
    "from dcase_util.containers import MetaDataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pkl file\n",
    "# pkl_file='../test_predictions/multitask_100epochs.pkl'\n",
    "# pkl_file='../test_predictions/dico_10epochs_MIL_cnn.pkl'\n",
    "pkl_file=\"results/testing/eval_880_dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286.pkl\"\n",
    "#pkl_file=\"results/testing/thomas_last.pkl\"\n",
    "#pkl_file='../test_predictions/dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286.pkl' # best: 24.46\n",
    "# pkl_file='../test_predictions/dico_10epochs_MIL_cnn_classif_cnn_70epochs_final_xtrain_f1_0.8762.pkl'\n",
    "# pkl_file='../test_predictions/dico_10epochs_MIL_cnn_crnn_adaptation.pkl'\n",
    "# pkl_file='../test_predictions/test_thresh_0_5_dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286.pkl'\n",
    "\n",
    "# pkl_file='../eval_predictions/eval_880_dico_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[\"Y0UN02RkbG_U_7.000_17.000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel\n"
     ]
    }
   ],
   "source": [
    "# format the curves to be used by the Encoder (need ALL curves)\n",
    "featRoot = \"/baie/corpus/DCASE2018/task4/FEATURES/\"\n",
    "metaRoot = \"/baie/corpus/DCASE2018/task4/metadata\"\n",
    "feat =  [\"mel\"]\n",
    "normalizer = None\n",
    "\n",
    "dataset = DCASE2018(\n",
    "        featureRoot=featRoot,\n",
    "        metaRoot=metaRoot,\n",
    "        features=feat,\n",
    "        expandWithUod=False,\n",
    "        validationPercent=0.2,\n",
    "        normalizer=normalizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Y0UN02RkbG_U_7.000_17.000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b561ce967edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestListFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcurves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbClass\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Y0UN02RkbG_U_7.000_17.000'"
     ]
    }
   ],
   "source": [
    "testListFile = [f[:-8] for f in dataset.testFileList]\n",
    "nbFrame = 431\n",
    "\n",
    "# rearange list of results\n",
    "results = []\n",
    "lfn = []\n",
    "for f in testListFile:\n",
    "    info = data[f]\n",
    "    \n",
    "    curves = np.array([[0]*dataset.nbClass for _ in range(nbFrame)], dtype=np.float32)\n",
    "    \n",
    "    for cls in info:\n",
    "        index = DCASE2018.class_correspondance[cls]\n",
    "        curves[:,index] = info[cls]\n",
    "        \n",
    "    results.append(curves)\n",
    "    lfn.append(f)\n",
    "\n",
    "results = np.array(results)\n",
    "\n",
    "print(testListFile[:5])\n",
    "print(lfn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smooting using the smooth moving average algorithm\n",
      "perform evaluation ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-24501081652d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_based_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_class_wise_average_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcwf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f_measure\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f_measure\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_based_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.1, low=0.05)#, smooth=\"smoothMovingAvg\")   # 6.66 %\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.05, low=0.05)#, smooth=\"smoothMovingAvg\")  # 20.75 %\n",
    "segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07, smooth=\"smoothMovingAvg\", window_len=19)  # 21.50 %\n",
    "\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07)#, smooth=\"smoothMovingAvg\")\n",
    "toEvaluate = encoder.parse(segments, dataset.testFileList)\n",
    "\n",
    "print(\"perform evaluation ...\")                                                                                                                                                                                                                                   \n",
    "with open(\"toEvaluate.csv\", \"w\") as f:                                                                                                                                                                                                                            \n",
    "    f.write(\"filename\\tonset\\toffset\\tevent_label\\n\")                                                                                                                                                                                                             \n",
    "    f.write(toEvaluate)                                                                                                                                                                                                                                           \n",
    "\n",
    "perso_event_list = MetaDataContainer()                                                                                                                                                                                                                            \n",
    "perso_event_list.load(filename=\"toEvaluate.csv\")                                                                                                                                                                                                                  \n",
    "\n",
    "ref_event_list = MetaDataContainer()                                                                                                                                                                                                                              \n",
    "ref_event_list.load(filename=dataset.meta_test)                                                                                                                                                                                                                   \n",
    "\n",
    "event_based_metric = event_based_evaluation(ref_event_list, perso_event_list)                                                                                                                                                                                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 880/880 [00:00<00:00, 1298.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(880, 64, 431, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the evaluation set\n",
    "featEvalPath = \"/baie/corpus/DCASE2018/task4/FEATURES/eval/mel\"\n",
    "featEvalList = os.listdir(featEvalPath)\n",
    "\n",
    "# load the meta data ----\n",
    "metaPath = \"/baie/corpus/DCASE2018/task4/metadata/eval.csv\"\n",
    "with open(metaPath, \"r\") as metaFile:\n",
    "    metadata = metaFile.read().splitlines()[1:]\n",
    "    \n",
    "metadata = [i.split(\"\\t\") for i in metadata]\n",
    "\n",
    "# load the features\n",
    "featEval = []\n",
    "for file in tqdm.tqdm(featEvalList):\n",
    "    path = os.path.join(featEvalPath, file)\n",
    "    feature = np.load(path)\n",
    "       \n",
    "    # preprocessing\n",
    "    feature = np.expand_dims(feature, axis=-1)\n",
    "    featEval.append(feature)\n",
    "    \n",
    "featEval = np.array(featEval)\n",
    "featEval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YX-jJxA53SFI_130.000_140.000', 'YBJimHxqGfig_50.000_60.000', 'YC7TihoHf_hM_20.000_30.000', 'Y-wQ8El8J_dE_30.000_40.000', 'Y63Qy15I3QGE_30.000_40.000']\n",
      "['Y6UY-HKyolKk_30.000_40.000', 'YKNFHL6rv_M4_50.000_60.000', 'YEmPv3XBRi-w_50.000_60.000', 'YKkPrgFi9X6U_20.000_30.000', 'Yv-J-jzNonoY_40.000_50.000']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(880, 431, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpListFile = [f[:-8] for f in featEvalList]\n",
    "print(tmpListFile[:5])\n",
    "print(list(data.keys())[:5])\n",
    "nbFrame = 431\n",
    "\n",
    "# rearange list of results\n",
    "results = []\n",
    "for f in tmpListFile:\n",
    "    info = data[f]\n",
    "    \n",
    "    curves = np.array([[0]*dataset.nbClass for _ in range(nbFrame)], dtype=np.float32)\n",
    "    \n",
    "    for cls in info:\n",
    "        index = DCASE2018.class_correspondance[cls]\n",
    "        curves[:,index] = info[cls]\n",
    "        \n",
    "    results.append(curves)\n",
    "\n",
    "results = np.array(results)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smooting using the smooth moving average algorithm\n",
      "perform evaluation ...\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "# segments = encoder.encode(results, method=\"hysteresis\", high=0.1, low=0.05, smooth=\"smoothMovingAvg\")   # 6.66 %\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.05, low=0.05)#, smooth=\"smoothMovingAvg\")  # 20.75 %\n",
    "segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07, smooth=\"smoothMovingAvg\", window_len=19)  # 21.50 %\n",
    "#segments = encoder.encode(results, method=\"hysteresis\", high=0.07, low=0.07)#, smooth=\"smoothMovingAvg\")\n",
    "toEvaluate = encoder.parse(segments, tmpListFile)\n",
    "\n",
    "print(\"perform evaluation ...\")                                                                                                                                                                                                                           \n",
    "with open(\"toto_toEvaluate.csv\", \"w\") as f:                    \n",
    "    f.write(\"filename\\tonset\\toffset\\tevent_label\\n\")                                                                                                                                                                                                             \n",
    "    f.write(toEvaluate)                                                                                                                                                                                                                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_fname='../submissions/0/sub0_10epochs_MIL_cnn_classif_cnn_100epochs_f1_0.8584_valf1_0.8286_macrof1_0.2446.txt'\n",
    "print(\"Saving final results in %s\"%submission_fname)                                                                                                                                                                                                                \n",
    "with open(submission_fname, \"w\") as f:                                                                                                                                                                                                                             \n",
    "    f.write(str(event_based_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in segments[0]:\n",
    "    print(\"cls: \", cls, segments[0][cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toEvaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
